[{"content":" 自己在初次尝试的过程中遇到很多错误，官网上又没有太多细节，网上其余资料也参差不齐，所以这里基于自己的经验做一个总结，以下步骤经过自己多次测试，供参考以便少走一些弯路。\n官网传送门：🚪Building Tomcat\ngithub 上克隆源代码并切换到指定版本分支\ngit clone https://github.com/apache/tomcat.git cd tomcat \u0026amp;\u0026amp; git checkout 10.0.x 安装ant\nbrew install ant 执行ant ide-intellij 构造IDEA project. 这一步主要是会生成一个.idea 目录, 以及下载一些依赖到${user.home}/tomcat-build-libs目录。\nant ide-intellij 命令结束后结尾处可看到让配置PATH VARIABLES。\nIDEA 配置PATH VARIABLES\nIDEA 安装ant 插件\nIDEA 打开tomcat 目录\n选中根目录tomcat 然后点open\nIDEA配置Project Structure, 将${user.home}/tomcat-build-libs添加到Libraries下面\n点击➕ —\u0026gt; Java —\u0026gt; 找到${user.home}/tomcat-build-libs —\u0026gt; 将下面的子文件夹全选\n运行ant, 编译\nant 运行完后会产生一个output目录\noutput/ ├── build ├── classes ├── i18n ├── jdbc-pool └── manifests Run configurations 以及设置VM options.\n找到org.apache.catalina.startup.Bootstrap, 运行其main方法，在run configurations 中添加VM options：\n-Dcatalina.home=/Users/hf/Downloads/tomcat-temp/tomcat/output/build -Dcatalina.base=/Users/hf/Downloads/tomcat-temp/tomcat/output/build 其中目录地址就是第8#中output 下面build 文件夹地址, 注意要求java 8 及以上。\n运行org.apache.catalina.startup.Bootstrap main方法，及浏览器访问http://localhost:8080/测试。\n看到这个页面说明启动成功。\n","date":"2024-03-05T11:36:36+08:00","image":"http://localhost:1313/posts/%E7%94%A8idea%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8tomcat%E6%BA%90%E7%A0%81/images/IMG_0283_hu7cde735718a1b4388ce891b20dc2d12c_12773497_120x120_fill_q75_box_smart1.JPG","permalink":"http://localhost:1313/posts/%E7%94%A8idea%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91%E5%90%AF%E5%8A%A8tomcat%E6%BA%90%E7%A0%81/","title":"用IDEA本地编译启动tomcat源码"},{"content":"HTTP压缩 http压缩通常是指服务器对即将要发送给客户端的响应进行压缩，再由客户端进行解压缩，以此达到减少传输的数据量，提升接口或页面性能的目的。\n常见的压缩算法\ndeflate: 基于deflate算法 gzip: GNU zip格式, 目前使用最为广泛 br: 一种新的开源压缩算法，专为HTTP内容的编码而设计 \u0026hellip; 由此就产生一个问题，服务器怎么知道应该用哪种压缩算法进行压缩？\n客户端和服务端就压缩方案进行协商 压缩方案协商为两步：\n客户端在发起请求的时候用Accept-Encoding 这个header来告诉服务端自己支持哪些算法，例如：\nAccept-Encoding: gzip, deflate, br 服务端会从客户端支持的算法中选择一个或多个对响应体进行压缩，然后通过Content-Encoding 来告诉客户端自己用了哪种算法来压缩，以便客户端再用对应的算法来解压缩，例如：\nContent-Encoding: gzip FAQ 如果客户端支持的压缩算法但服务端都不支持那怎么办？\n那就不压缩，爱咋咋。这时候在响应头里就没有显示的Content-Encoding这个header了，或者说会采用它的默认值identity, 表明没有对响应体进行压缩。\n常看到响应头里有Vary:Accept-Encoding, 这是什么？\nVary 首部字段常常在进行主动协商的响应中发送，用于指示选择算法中使用了请求信息的哪些部分。在 HTTP 中，主动协商是指服务器根据客户端的能力和偏好，以及资源的特性，选择最合适的响应进行发送。\n简而言之，当服务器基于客户端请求的一些特定信息（比如 Accept-Encoding）来选择合适的响应时，它可以通过 Vary 首部字段来明确说明使用了哪些请求信息。这对于缓存和代理服务器来说尤为重要，因为它们可以根据 Vary 字段中列出的请求头部信息来判断是否可以使用缓存的响应，或者是否需要重新向源服务器请求新的响应。更多详细信息可以参考RFC 7231 section 7.1.4\n类似的还看到Transfer-Encoding, 这个又是什么？\nContent-Encoding 用于描述消息体的压缩方式，而 Transfer-Encoding 则用于指示消息传输时的编码方式，比如Transfer-Encoding:chunked表明将消息进行分块传输。比如Transfer-Encoding:identity表明消息体的长度已知且未进行编码\n等等，分块传输是什么以及为什么要有分块传输？\n分块传输 分块传输顾名思义就是将响应消息体分多次发送，一次发送一部分数据。我们先来了解一下与之对应的“一次性传输”，也就是一次性发送所有数据。\nHTTP协议是应用层协议，客户端和服务端进行交互是建立在TCP链接之上，现在假设服务端要向客户端传送数据，在传送完一段数据后下一步客户端该干嘛呢？\n站在客户端视角的第一个疑问就是：这个数据传送完了吗？\n所以为了让客户端知道数据是否传送完毕，一种方案就是服务端在传送响应体之前计算消息的长度，然后把这个长度通过Content-Length 这个响应头告诉客户端，在客户端收到一部分数据后它可以计算收到的数据长度，如果和Conent-Length的值一样，那就可以认为数据传送完了然后客户端下一步就可以做自己想做的事(比如关闭TCP链接，或者发起一个新的请求)。 这就是一次性传输及Content-Length 在这个过程中发挥的作用。另一种方案是服务端在发送完数据就关闭TCP链接，这样客户端看到服务端关闭了链接，也可以约定只要你关闭链接我就认为数据传输完了，但是基本上不会这么做。\n如果Content-Length 和真实长度不一致会怎样？\n如果Content-Length小于真实长度，则客户端会对内容进行裁剪，对外表现就是数据不完整。\n如果Content-Length小于真实长度，则客户端请求会一直pengding, 因为它认为响应还没有结束。\n在第一种方案中需要提前计算消息长度，对于普通的较小的文本还好说，但如果消息很长，很大，比如一些文件，这个计算过程很费时间或者空间，在客户端看来这个请求的响应就很慢。所以就有了分块传输的做法，不计算长度，把数据分成不同的小块逐步发送。\n例如：\nsocket.getOutputStream().write(\u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;Transfer-Encoding: chunked\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;Content-Type: text/plain\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;5\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;123\\r\\n\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().flush() socket.getOutputStream().write(\u0026#34;2\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;ab\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().flush() socket.getOutputStream().write(\u0026#34;0\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;13\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().write(\u0026#34;am I ignored?\\r\\n\u0026#34;.toByteArray()) socket.getOutputStream().flush()分块传输方法： 需要在响应头中添加：Transfer-Encoding: chunked 响应头结束需要添加CRLF(\\r\\n)表示响应体的开始 每一个响应块第一行表示该块的长度(结尾是CRLF)，然后是数据本身，遇到CRLF,表明块结束，若第一行长度和真实数据长度不一致通常客户端会解析失败 最后一个块必须长度为0，不包含任何数据并依旧以CRLF结尾。 Tomcat 中的分块传输与响应压缩 tomcat HTTP压缩功能手动开启方式如下：在server.xml中\n\u0026lt;Connector port=\u0026#34;8080\u0026#34; protocol=\u0026#34;HTTP/1.1\u0026#34; connectionTimeout=\u0026#34;20000\u0026#34; compression=\u0026#34;on\u0026#34; \u0026lt;!-- 开启压缩 --\u0026gt; compressionMinSize=\u0026#34;10\u0026#34; \u0026lt;!-- 压缩阀值, 当消息长度超过的时候才进行压缩 --\u0026gt; \u0026lt;!-- 压缩类型 --\u0026gt; compressableMimeType=\u0026#34;text/html,text/xml,text/javascript,application/javascript,text/css,text/plain,text/json\u0026#34; redirectPort=\u0026#34;8443\u0026#34;/\u0026gt; 更多详细配置方式可参考Apache Tomcat 10 Configuration Reference\n压缩就会更好吗？不是，压缩意味着服务端更多的资源消耗\n用来测试的Servlet\nclass TestCompressionServlet : HttpServlet() { override fun doGet(request: HttpServletRequest, response: HttpServletResponse) { val stringBuilder = StringBuilder() for (i in 1 until 10000000) { stringBuilder.append(\u0026#34;Hi,\u0026#34;) } response.contentType=\u0026#34;text/html\u0026#34; response.writer.write(stringBuilder.toString()) } } 这里会向客户端返回一个很长的字符串，在《Tomcat架构原理解析》 中我们说到servelt 通过response.writer.write 写入响应的时候其实是先写入org.apache.catalina.connector.Response内部维护的CharBuffer中，最后会把CharBuffer转为ByteBuffer中然后交给SocketHandler的writeBuffer最后才会写入socket中。\n我们现在要写入的是一个很长的字符串，而Buffer却只有8KB, 怎么办？Tomcat 是这么处理的：\n在写入CharBuffer 后，如果CharBuffer满了会将CharBuffer 中的数据flush 到ByteBuffer, 然后清空CharBuffer，源码位置：org.apache.catalina.connector.OutputBuffer#write\n剩下的数据继续写入CharBuffer, 重复1的步骤\n如果在#1中，ByteBuffer也满了，会flush 数据到org.apache.coyote.Response中并清空ByteBuffer，调用它的write方法， 最终会调用到Http11OutputBuffer的doWrite方法。源码位置：org.apache.coyote.http11.Http11OutputBuffer#doWrite\n这时候Http11OutputBuffer如果发现Response 还没commit, 会通过action调用Http11Processor 来commit response，这一步会准备响应的响应行(包括协议和状态码，例如：HTTP/1.1 200）以及响应头, 然后将这部分信息写到Http11OutputBuffer的headerBuffer中， headerBuffer的大小可进行配置，若超出大小则抛BufferOverflowException。 然后通过outputBuffer.commit()将这部分数据存到socketBufferHandler的writeBuffer中，如果writeBuffer也满了则会写到socket中。 在3#中准备响应头的时候(源码位置：org.apache.coyote.http11.Http11Processor#prepareResponse)，如果开启了压缩功能：\n添加Vary: accept-encoding header。 根据Request中accept-encoding这个header传过来的值判断客户端是否支持gzip，若支持则设置contentLength为-1， 若不支持那就不压缩。也就是说tomcat 默认只支持gzip压缩 如果contentLength不为-1，则添加ChunkedOutputFilter为activeFilters 如果发现支持gzip, 则会添加GzipOutputFilter为activeFilters 然后继续回到3#中Http11OutputBuffer的doWrite 方法，在commit response 之后会调用GzipOutputFilter的doWrite方法, 接着6#。\nGZIPOutputStream的doWrite方法会通过调用native 方法来将数据读取到内存中，然后进行压缩并存到GZIPOutputStream内部的byte数组buf中。\n压缩的逻辑由JDK封装的java.util.zip.Deflater 来调用native实现 但是此处不会一有数据就马上进行压缩(NO_FLUSH 模式)，而是数据累计到一定量之后才进行压缩, 具体多少数据量才压缩由Deflater决定. 如果压缩后的数据一个buf 装不下, 就将buf 传给ChunkedOutputFilter(第7#），继续往buf里填充数据。\n当所有现阶段已压缩的数据都交给ChunkedOutputFilter后，GzipOutputFilter#doWrite方法才算结束\npublic void write(byte[] b, int off, int len) throws IOException { ... if (!def.finished()) { def.setInput(b, off, len); while (!def.needsInput()) { deflate(); } } } 源码位置：org.apache.coyote.http11.filters.GzipOutputFilter#doWrite 及java.util.zip.Deflater#deflate(byte[], int, int, int)\n将到buf中的byte传给ChunkedOutputFilter，调用ChunkedOutputFilter的doWrite方法。ChunkedOutputFilter会构造需要分开传输的块，然后将块写入到socketBufferHandler的writeBuffer中。如果writeBuffer也满了则会写到socket中，开始分块传输。\n继续1#，2#，5#，6#, 7#直到servlet write结束。\n经过前面几步后这个长响应体大部分都已经被传输到客户端，还有一小部分可能存在CharBuffer和ByteBuffer中，servlet 的service 方法也会执行结束，来到Adapter的response.finishResponse() 阶段，源码位置：org.apache.catalina.connector.Response#finishResponse\n如果CharBuffer中有数据则flush到ByteBuffer，如果ByteBuffer满了则继续3#，5#。 调用doFlush方法，再次flush CharBuffer 和flush ByteBuffer。 通过Close Action调用Http11Processor的finishResponse方法，然后调用到GzipOutputFilter的end方法，标记finish为true。 采用FINISH模式继续压缩，此时会把剩下数据继续压缩(因为有可能内存中累计的数据量还没到deflater的标准），压缩后的数据依旧存到buf中并继续第7#，8#步。源码位置：java.util.zip.GZIPOutputStream#finish * 直到内存中所有响应数据压缩并写到buf完成，标记finished 为true。 * 如果buf满载的情况下，块中第一行标明数据长度会是512，用十六进制200表示。 最后按照GZIP 算法要求构造数据尾部，并继续传递给ChunkedOutputFilter，至此全部的压缩数据都已处理完成 上述servlet开启压缩前，浏览器中显示响应大小约为30MB,\n开启压缩后传输体积减少了1000倍！\n","date":"2024-02-29T13:38:34+08:00","image":"http://localhost:1313/posts/tomcat-http-%E5%8E%8B%E7%BC%A9%E4%B8%8E%E5%88%86%E5%9D%97%E4%BC%A0%E8%BE%93/images/IMG_0942_hu64891f67de11c90bd86988b705ef8032_13009892_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/posts/tomcat-http-%E5%8E%8B%E7%BC%A9%E4%B8%8E%E5%88%86%E5%9D%97%E4%BC%A0%E8%BE%93/","title":"tomcat http 压缩与分块传输"},{"content":"Tomcat自1998年问世以来因为其高性能，免费等特点广受Java爱好者的喜爱，但在Springboot等微服务框架成为技术主流后的今天，tomcat似乎逐渐\u0026quot;消失\u0026quot;在大众的视线中，你还在用tomcat吗？我相信对于大部分java web developer来说这个问题的答案是Yes, 因为Springboot web starter默认集成的就是tomcat。\n本文尝试从\u0026quot;为什么浏览器发出的HTTP请求可以到达我们的Controller\u0026quot;这一基本问题出发，由浅入深，由点到面的方式先从整体的角度来梳理tomcat的架构原理，再到以一个HTTP/1.1 请求为例来分析tomcat作为一个HTTP web服务器和Servlet容器它是怎么实现的，最后回归这个问题梳理springboot是如何与tomcat集成的。其中涉及大量的源码解析，请留意涉及源码解析的部分都是基于tomcat 10.x 来进行。希望能给那些对tomcat原理感兴趣的同学提供一些视角和参考。\n什么是Tomcat Tomcat的核心功能 tomcat是一个==web应用服务器==和==Servlet容器==，它还是 Jakarta Servlet、Jakarta Server Pages、Jakarta Expression Language、Jakarta WebSocket、Jakarta Annotations 和 Jakarta Authentication 规范的开源实现。\n这里有两个重点，web应用服务器和Servlet容器。分别对应了它的两个核心功能：\n什么是Web服务器, 说白了，它的作用就是将主机上的某个资源映射成一个URL供外界访问。\n处理 Socket 连接，负责网络字节流与 Request 和 Response 对象的转化。 加载并管理 Servlet ，并将请求交给Servlet处理。 但web服务器 和servlet容器依旧显的有些抽象，他们到底是什么？\n理解什么是tomcat 就是理解tomcat到底帮我们做了什么。我们在上手做Java web项目时往往都是基于框架比如springboot,来专注于业务代码开发，我们知道按照springboot 的规则来定义一些controller, 就可以接收到从浏览器发过来的HTTP请求。\n但是，==为什么controller可以收到并处理客户端发过来的请求==?\n答案是因为gradle 或者maven 中有spring-boot-starter-web 这个依赖，而这个依赖默认帮我们集成了Tomcat。在进一步理解tomcat是怎么帮我接收并解析HTTP请求之前，我们先设想，如果没有框架，站在tomcat开发者的角度来思考我们要自己实现下面这样的功能应该要怎么做。\nScenario: Receive and Process HTTP Request Given the system is running When a valid HTTP request is received Then the system should successfully parse the HTTP request And extract the request path, parameters, method, and body if present And generate an appropriate HTTP response And include the correct HTTP status code indicating successful processing And include the expected response body format and data if applicable And include the appropriate HTTP headers in the response (e.g., Content-Type) 理解HTTP 请求的本质 HTTP请求是客户端在向服务端请求某个资源时，向服务端发送的符合HTTP协议规范的数据，下面给出一个完整的GET 请求示例\nGET /sample HTTP/1.1 Host: www.example.com Accept: application/json 手写最简版Tomcat 如何发起HTTP请求？ 发起HTTP请求其实就意味着我们要把这部分数据发送给服务端。\n那我们要怎么把这部分数据发送给服务器呢？这其实涉及计算机网络的基础，计算机之间是如何通信的。\n假设有一个主机A，有一个主机B，A需要通过浏览器发送HTTP请求给B的Java 进程。那么经历如下步骤：\n1.HTTP 是应用层协议，在发送数据之前，A中的浏览器需要和B中的Java 进程建立一个TCP 链接。\n那我们如何建立TCP 链接呢，其实这部分工作是由应用层的底层库去帮我们来做的。以Java 为例，这个类库就叫做Socket。它也是在网络通信中的一个种抽象概念，从Java的角度来理解建立一个TCP 链接其实就是生成了一个Socket 对象，下面是一个建立TCP链接示例：\nval socket = Socket(\u0026#34;google.com\u0026#34;, 443) println(socket.isConnected) 当上述代码输出true 就表明已经建立了链接，这底层由JDK 调用操作系统API 来实现。\n2.链接建立后，我们就可以流式的传输数据，发起HTTP请求其实就是向一个地方去写符合HTTP规范数据。\n向哪里写？依旧以Java 为例，上面说到在网络中的通信我们有个抽象的东西叫Socket, 而JDK 类库帮我们做了底层实现，因此我们写数据读数据还是面向Socket。下面是向socket 数据的示例：\n# 写入一个字节数组 socket.getOutputStream().write(\u0026#34;Ping!\u0026#34;.toByteArray()) #也可以写入单个字节 socket.getOutputStream().write(71) 这里的byte,71根据字符编码可以解析成对应的字符，71通常对应的是字母G, 关于字符编码请参考我的另一篇笔记：ASCII、Unicode和UTF-8与字符编码\n3.我们向Socket写入数据后，剩下的也会由jvm和操作系统帮我们处理，通过通信网络传输到主机B上。\n至此，我们已经知道了客户端发起一个HTTP请求的时候干了什么，不同的应用程序底层对于Socket可能有不同实现, 但这部分底层细节其实往往不用我们操心，我们只需要知道发起HTTP请求就是发送了一段符合HTTP协议规范的数据到服务端。关于更多HTTP 协议的内容请参阅相关文档。\n如何接收并处理HTTP 请求? 端口监听 上面说到发起HTTP 请求其实就是发送一段数据给服务端，那为什么可以发送数据呢？因为我们在发送数据之前建立了TCP 链接，而TCP 是一种面向链接的可靠的协议，那为什么可以建立TCP链接？Socket(\u0026quot;google.com\u0026quot;, 443) 这段代码中的两个参数是什么含义？\n域名会被DNS服务器解析成ip, 用来在网络传输中找到对应的主机，而443则表示服务器正在监听的端口， 注意一个进程可能会用到多个端口。\n下面我们看怎么在Java 中开启这样的端口监听。\nval serverSocket = ServerSocket(8080) println(\u0026#34;Server started successfully, listening on port: 8080\u0026#34;) 我们用到了ServerSocket这个类，它提供了一种机制，使得Java应用程序能够监听客户端的连接请求，并在连接建立后进行通信。而这底层也是有JDK调用操作系统API 实现。\n1.它建立了一个专门侦听某端口的socket\n2.每次成功与客户端握手后,会创建一个针对当前客户的新socket\n3.后续程序通过这个socket与客户端进行数据交互\n读取数据并解析成HTTP 请求 再次说到发起一个HTTP请求就是发送了一段数据给服务器，我们看怎么样读取这份数据。\n# 建立ServerSocket后调用accept 方法来接收请求，在有请求到来之前这个方法会一直阻塞，并且为了处理多次请求，一般会循环调用 val socket = serverSocket.accept() # 上述方法返回了Socket, 这和我们从客户端建立链接时看到的Socket 是一样的，因为说了，网络上的通信我们都是面向Socket val bytes = socket.getInputStream().let { val bytes = ByteArray(it.available()) it.read(bytes) bytes } println(bytes.decodeToString()) 在10行运行完后我们可以在控制台看到类似下面这样的输出：\nGET /sample HTTP/1.1 Host: www.example.com Accept: application/json 这正是我们在客户端发起的HTTP 请求！\n然后我们就可以去解析这段文本，包括去解析请求行，请求头，请求体等基于字符串操作去进行具体的业务处理。\n如何响应 响应是由服务端向客户端响应，响应就是回传满足HTTP 协议的规范数据，同样是面对socket 对象进行，JDK 和操作系统会帮我们处理底层和剩下的事。\nsocket.getOutputStream().write( (\u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; + \u0026#34;Content-Type: text/plain\\r\\n\u0026#34; + \u0026#34;Content-Length: 25\\r\\n\u0026#34; + \u0026#34;\\r\\n\u0026#34; + \u0026#34;Hello, World and /sample!\u0026#34; ).toByteArray() ) 客户端接收到这份数据后便可以根据根据HTTP 协议解析数据然后作对应处理。\n以上就是自己去实现这个需求要做的事，然而我们平时在使用springboot开发时几乎不需要关心这些，因为集成的tomcat会帮我们处理，这正是Tomcat 的核心功能之一：\n==处理 Socket 连接，负责网络字节流与 Request 和 Response 对象的转化==。\n最简版Tomcat 将以上步骤再串起来我们就可以自己去实现tomcat， 注意，真正的tomcat实现和功能要比这个复杂的多，但理解这部分内容对于我们理解什么是Tomcat很重要，因为tomcat在做着类似的事情。\n测试先行\n@Test fun `should successfully process valid HTTP request`() { // Given MyHttpServer(TEST_PORT).start() // When // 发起HTTP 请求 val socket = sendRequest() // Then assertEquals( \u0026#34;HTTP/1.1 200 OK\\r\\nContent-Type: text/plain\\r\\n\u0026#34; + \u0026#34;Content-Length: 25\\r\\n\\r\\nHello, World and /sample!\u0026#34;, decodeResponse(socket) ) } /** * 1.建立socket连接 * 2.向socket中写入符合HTTP规范的数据 * 3.返回socket */ private fun sendRequest( httpRequest: String = \u0026#34;GET /sample HTTP/1.1\\r\\n\u0026#34; + \u0026#34;Host: localhost\\r\\n\u0026#34; + \u0026#34;Accept: application/json\\r\\n\\r\\n\u0026#34; ): Socket { val socket = Socket(Constants.LOCAL_HOST, Constants.TEST_PORT) socket.getOutputStream().write(httpRequest.toByteArray(Charset.defaultCharset())) return socket } SampleHttpServer类\n负责创建ServerSocket监听端口 接收客户端的请求，从Socket 中读取数据解析成Request对象 构建Response 对象并向Socket中写入数据 package com.fan import java.net.ServerSocket import java.net.Socket import java.net.SocketException import java.nio.charset.StandardCharsets class SampleHttpServer(private val port: Int) { private lateinit var serverSocket: ServerSocket private var isRunning = true fun start() { createServerSocket(port) println(\u0026#34;${currentThreadName()}Server started successfully, listening on port $port\u0026#34;) Thread { while (isRunning) { val clientSocket = acceptClientConnection(serverSocket) clientSocket?.let { try { handleClientRequest(clientSocket) } catch (e: Exception) { e.printStackTrace() } finally { closeSocket(clientSocket) } } } }.start() } private fun closeSocket(clientSocket: Socket) { checkIfSocketClosed(clientSocket) if (!clientSocket.isClosed) { clientSocket.close() checkIfSocketClosed(clientSocket) } } private fun checkIfSocketClosed(clientSocket: Socket) { println(\u0026#34;${currentThreadName()}client socket closed? ${clientSocket.isClosed}\u0026#34;) } private fun createServerSocket(port: Int) { this.serverSocket = ServerSocket(port) } private fun acceptClientConnection(serverSocket: ServerSocket): Socket? { try { val clientSocket = serverSocket.accept() println(\u0026#34;${currentThreadName()}Accepted client connection from: ${clientSocket.inetAddress}\u0026#34;) return clientSocket } catch (e: SocketException) { //socket maybe closed from client, ignore println(\u0026#34;${currentThreadName()} ${e.message}\u0026#34;) } return null } private fun handleClientRequest(clientSocket: Socket) { val requestBytes = readBytesFromSocketInputStream(clientSocket) println(\u0026#34;${currentThreadName()}Received bytes from client:${requestBytes.contentToString()}\u0026#34;) val httpRequest = parseBytesToHttpRequest(requestBytes) val httpResponse = buildResponse(httpRequest) sendResponseToClient(httpResponse, clientSocket) } private fun readBytesFromSocketInputStream(socket: Socket): ByteArray { return socket.getInputStream().let { val bytes = ByteArray(it.available()) it.read(bytes) bytes } } private fun parseBytesToHttpRequest(bytes: ByteArray): Request { val plainRequest = String(bytes, StandardCharsets.UTF_8) println(\u0026#34;${currentThreadName()}Received request:\\r\\n--------------\\r\\n$plainRequest\\r\\n--------------\u0026#34;) val httpMethod = extractHttpMethod(plainRequest) val uri = extractUri(plainRequest) val protocol = extractProtocol(plainRequest) return Request(httpMethod, protocol, uri) } private fun extractHttpMethod(plainRequest: String): String { return plainRequest.substring(0, plainRequest.indexOf(\u0026#34; \u0026#34;)) } private fun extractUri(plainRequest: String): String { val start = plainRequest.indexOf(\u0026#34; \u0026#34;) + 1 val end = plainRequest.indexOf(\u0026#34;HTTP\u0026#34;) - 1 return plainRequest.substring(start, end) } private fun extractProtocol(plainRequest: String): String { val start = plainRequest.indexOf(\u0026#34;HTTP\u0026#34;) + 5 val end = plainRequest.indexOf(\u0026#34;\\r\\n\u0026#34;) return plainRequest.substring(start, end) } private fun buildResponse(request: Request): Response { val body = \u0026#34;Hello, World and ${request.uri}!\u0026#34; return Response( statusLine = \u0026#34;HTTP/1.1 200 OK\u0026#34;, headers = \u0026#34;Content-Type: text/plain\\r\\nContent-Length: ${body.length}\u0026#34;, body = body ) } private fun sendResponseToClient(response: Response, socket: Socket) { val responseBytes = response.toString().toByteArray() socket.getOutputStream().write(responseBytes) println(\u0026#34;${currentThreadName()}Response sent to client.\u0026#34;) } private fun currentThreadName() = \u0026#34;[${Thread.currentThread().name}] \u0026#34; fun stop() { isRunning = false if (::serverSocket.isInitialized) { serverSocket.close() } } } Request 和 Response\npackage com.fan data class Request( val method: String, val protocol: String, val uri: String ) data class Response( val statusLine: String, val headers: String, val body: String ) { override fun toString(): String { return statusLine + \u0026#34;\\r\\n\u0026#34; + headers + \u0026#34;\\r\\n\\r\\n\u0026#34; + body } } 源码地址: https://github.com/woaihuangfan/how-tomcat-works.git\n这是采用大部分人较为熟悉BIO的的实现方式，而从tomcat 8.0开始会默认使用NIO的方式来处理请求，关于NIO的demo请在源码中寻找NioHttpServer。\n什么是Servlet web开发，我们其实主要处理三件事：\n接收请求： 从socket 中读取数据 处理请求：具体的业务逻辑，比如针对数据库的curd 响应: 向socket 中写入数据 #1和#3操作是基础操作，大家都要干这事且干的方式基本都一样，无非就是针对socket的网络编程，但是处理请求的部分是不同的，因为业务逻辑千差万别万别。\n#1中读取到数据后，需要交给一个东西(对象)让2#来处理请求，这个东西处理完请求后还要生成响应交给#3， 我们把这个东西(对象) 叫Servlet。Servlet 就是#1 和#2， #2和#3之间的这个中间层。\n一个有意思的问题是，处理请求时只能用一个对象吗？当然不是，我们处理请求可能需要用到多个对象（比如controller，service), 但这些controller service 对象能叫servlet吗？。\n所以这三件事再具体一点总结下就是：\n接收请求： 从socket 中读取数据， ==并把数据交给Servlet== 处理请求：Servlet处理具体的业务逻辑，比如针对数据库的curd，然后生成响应 响应: 获取Servlet生成的响应并向socket 中写入数据 1和3的操作大家可以共用，因此可以放到框架里，#2需要我们自己去实现，现在问题来了，我们知道要写Servlet 去处理请求，但是我怎么知道该怎么写？比如需用什么方法命名，参数等等才能被框架调用到。\n有同学可能说取决于你用什么框架， 但如果想换框架怎么办？\n因此我们就有了Servlet规范，来指导框架怎么写，servlet怎么写，以确保不同的Servlet容器（例如Tomcat、Jetty等）之间的兼容性。比如:\n规定了所有Servlet类都必须实现javax.servlet.Servlet 这个接口\n定义了Servlet的生命周期，比如规定每一个servlet 都必须有 init()、service()、destroy()，\n描述了Servlet容器的职责和功能，比如当请求来了会调用Servlet实例的service方法\n等等。更多详细的规范请参阅\n⚠️ Servlet API 的包名自2020年12月Jakarta EE 9 发布后已经从 javax.servlet 更改为 jakarta.servlet\n相信很多人在学java web 时一开始都会去学怎么写一个Servlet.\n规范、约定的思想随处可见，这个世界万物的运行本质上也是基于规范规则。\n再去理解什么是tomcat的时候发现tomcat 其实也实现了Servlet规范， 也可以理解为什么说Tomcat 是servlet 容器了。\n小结\nServlet 是一段程序 需要符合Servlet规范 它主要用于处理和响应HTTP 请求 运行在支持Servlet规范的容器中 Tomcat 的工作原理 虽然应用大部分应用都是基于springboot及其默认内嵌的tomcat进行开发，但是脱离复杂的spring把tomcat作为独立部署的中间件可以更好的来帮助我们来学习和了解tomcat。\n下载Tomcat curl https://dlcdn.apache.org/tomcat/tomcat-10/v10.1.18/bin/apache-tomcat-10.1.18.zip -o apache-tomcat-10.1.18.zip 解压后可以看到如下目录结构：\n自定义一个Servlet\n以下代码由kotlin 实现，注意HttpServlet 已经实现了jakarta.servlet 所以此处我们只需要继承HttpServlet就行。\nclass DemoServlet : HttpServlet() { override fun doGet(request: HttpServletRequest, response: HttpServletResponse) { response.writer.write(\u0026#34;Pong!\u0026#34;) } } 编译上述代码，得到class文件\n由于是kotlin 代码，所以我们可以用IDEA 进行编译，也可以用离线的kotlin编译器，我是选择的前者。\n将class 文件拷贝到tomcat指定目录\n在webapp 下创建一个目录命名为my-app， 并在my-app创建如下目录结构：\nmy-app └── WEB-INF ├── classes │ └── org │ └── fan │ └── DemoServlet.class ├── lib │ ├── annotations-13.0.jar │ └── kotlin-stdlib-1.9.21.jar └── web.xml web.xml 的内容如下\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\u0026#34; version=\u0026#34;3.1\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;DemoServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.fan.DemoServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;DemoServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/ping\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; 这一步就是配置映射规则，让符合规则的请求被指定的servlet处理。\n通过bin目录下的脚本启动Tomcat\nchmod -R +x ./bin ./bin/startup.sh 浏览器访问http://localhost:8080/my-app/ping\n可以看到我们只要把自己写的Servlet 按照tomcat 的规则放到指定目录下，然后运行tomcat 我们写的Servlet就可以处理请求，下面解释下我刚刚创建的目录结构的作用。\nclasses 这个目录存放我们自己写的Servlet编译后的字节码文件\n什么是字节码文件？里面存的是什么？长什么样子？\nlib 存放我们需要用到的依赖，因为我是用kotlin编写的，所以需要用到相关依赖\nweb.xml 存放Tomcat相关配置，上面我们只告诉了tomcat 把URI为/ping 的请求交给 DemoServlet处理\n至此我们可以看到tomcat 至少做了如下的事：\n监听网络端口 接受网络请求 读取网络数据 根据HTTP 协议解析数据 加载class 文件及jar 文件 调用DemoServlet的doGet 方法 将响应的字节流写回给浏览器 要做这些事肯定不会像我们demo版代码中那么简单，肯定经过设计的，但是无论怎么设计，每个接口和模块都有它自己的职责和要处理的事情，下面先看看tomcat 的整体架构。\nTomcat架构 Tomcat整体架构是一种分层的结构，我们先看一个结论图(来源于网络)， 后面我在分析源码的时候会逐渐把源码和这个图对应起来。\n在这小节我们可以先只关注Server、 Service、Connector、Engine、Host、Context、Wrapper， 记住这几个组件名字及他们的层级关系, 其中除Connector没有抽象出接口外，其余也都对应了tomcat中几个顶级接口名字(例如org.apache.catalina.Server), 而StandardXXX 是这些接口的实现。\n注意：下文贴出的源代码部分都是精简过后的关键代码、个人认为是作为理解tomcat的必读部分。过完必读部分后，若能下载全部源码通过debug来了解更多细节则更佳，关于如何在本地编译并启动tomcat源码可以参考我的另一篇：如何用IDEA本地编译启动tomcat\nStandardServer public final class StandardServer extends LifecycleMBeanBase implements Server { ... private Catalina catalina = null; /** * The set of Services associated with this Server. */ private Service services[] = new Service[0]; ... @Override public void addService(Service service) { ... synchronized (servicesLock) { Service results[] = new Service[services.length + 1]; // 将services 中的值拷贝到results System.arraycopy(services, 0, results, 0, services.length); results[services.length] = service; services = results; ... } } @Override public void addConnector(Connector connector) { synchronized (connectorsLock) { connector.setService(this); Connector results[] = new Connector[connectors.length + 1]; System.arraycopy(connectors, 0, results, 0, connectors.length); results[connectors.length] = connector; connectors = results; } ... } @Override public void setCatalina(Catalina catalina) { this.catalina = catalina; } ... } StandardService public class StandardService extends LifecycleMBeanBase implements Service { ... private Engine engine = null; /** * The \u0026lt;code\u0026gt;Server\u0026lt;/code\u0026gt; that owns this Service, if any. */ private Server server = null; /** * The set of Connectors associated with this Service. */ protected Connector connectors[] = new Connector[0]; ... @Override public void setContainer(Engine engine) { ... this.engine = engine; if (this.engine != null) { this.engine.setService(this); } ... } @Override public void setServer(Server server) { this.server = server; } @Override public void addConnector(Connector connector) { synchronized (connectorsLock) { connector.setService(this); Connector results[] = new Connector[connectors.length + 1]; System.arraycopy(connectors, 0, results, 0, connectors.length); results[connectors.length] = connector; connectors = results; } ... } ... } StandardEngine public class StandardEngine extends ContainerBase implements Engine { /** * The \u0026lt;code\u0026gt;Service\u0026lt;/code\u0026gt; that owns this Engine, if any. */ private Service service = null; ... @Override public void addChild(Container child) { // Engine的Child 必须是Host if (!(child instanceof Host)) { throw new IllegalArgumentException (sm.getString(\u0026#34;standardEngine.notHost\u0026#34;)); } // 调用父类ContainerBase中的实现 super.addChild(child); } ... } StandardHost public class StandardHost extends ContainerBase implements Host { ... @Override public void addChild(Container child) { // Host的Child必须是Context if (!(child instanceof Context)) { throw new IllegalArgumentException (sm.getString(\u0026#34;standardHost.notContext\u0026#34;)); } ... // 调用父类ContainerBase中的实现 super.addChild(child); } ... } StandardContext public class StandardContext extends ContainerBase implements Context, NotificationEmitter { ... @Override public void addChild(Container child) { // Global JspServlet Wrapper oldJspServlet = null; if (!(child instanceof Wrapper)) { throw new IllegalArgumentException (sm.getString(\u0026#34;standardContext.notWrapper\u0026#34;)); } ... // 调用父类ContainerBase中的实现 super.addChild(child); ... } ... } StandardWrapper public class StandardWrapper extends ContainerBase implements ServletConfig, Wrapper, NotificationEmitter { ... /** * Refuse to add a child Container, because Wrappers are the lowest level * of the Container hierarchy. * * @param child Child container to be added */ @Override public void addChild(Container child) { // StandardWrapper是层级的最底层，拒绝添加child throw new IllegalStateException (sm.getString(\u0026#34;standardWrapper.notChild\u0026#34;)); } ... } 我们可以看到StandardEngine，StandardHost，StandardContext, StandardWrapper都继承了ContainerBase且都实现了Container 接口，他们addChild 的时候都调用了父类方法，child 维护在父类的children属性中.\npublic abstract class ContainerBase extends LifecycleMBeanBase implements Container { ... /** * The parent Container to which this Container is a child. */ protected Container parent = null; protected final HashMap\u0026lt;String, Container\u0026gt; children = new HashMap\u0026lt;\u0026gt;(); ... @Override public void addChild(Container child) { ... addChildInternal(child); ... } private void addChildInternal(Container child) { ... synchronized(children) { if (children.get(child.getName()) != null) { throw new IllegalArgumentException( sm.getString(\u0026#34;containerBase.child.notUnique\u0026#34;, child.getName())); } child.setParent(this); // May throw IAE children.put(child.getName(), child); } ... } ... } 看完以上几个类的部分核心代码就会理解这种像套娃一样的分层设计。\n依次往下，一个Server 包含一个或多个Service, 一个Service包含一个Engine和一个或多个connector，一个Engine 可以包含多个Host, 一个Host 可以包含一个或多个Context, 一个Context 可以包含多个Wrapper, 从Engine开始都实现了Container 接口。\n化抽象为具体\n现在Server, service, engine 等我们从技术角度理解了他们是一个个的接口，或者说技术组件，依旧是一种抽象的概念，那如何从业务角度理解他们是干什么的？\nServer可以理解为一个tomcat server 实例; Service将一个或多个连接器与一个Engine相关联; Engine 用来管理多个虚拟主机； Host 代表的是一个虚拟主机，可以给 Tomcat 配置多个虚拟主机地址； Context 表示一个 Web 应用程序，而一个虚拟主机下可以部署多个 Web 应用程序; Wrapper 表示一个 Servlet, 一个 Web 应用程序中可能会有多个 Servlet； 并且可以发现，\n在这个层级结构中，子节点中也维护了父节点，形成了双向链表和对象树。\n每一层的组件都实现了Lifecycle接口。\n再看看Tomcat 配置文件可以帮助我们更好的来理解这个层次关系。以下配置文件节选自默认的conf/server.xml文件。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Server port=\u0026#34;8005\u0026#34; shutdown=\u0026#34;SHUTDOWN\u0026#34;\u0026gt; \u0026lt;Service name=\u0026#34;Catalina\u0026#34;\u0026gt; \u0026lt;Connector port=\u0026#34;8080\u0026#34; protocol=\u0026#34;HTTP/1.1\u0026#34; connectionTimeout=\u0026#34;20000\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; \u0026lt;Engine name=\u0026#34;Catalina\u0026#34; defaultHost=\u0026#34;localhost\u0026#34;\u0026gt; \u0026lt;Host name=\u0026#34;localhost\u0026#34; appBase=\u0026#34;webapps\u0026#34; unpackWARs=\u0026#34;true\u0026#34; autoDeploy=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/Host\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; 同时引入两个问题，\n这个对象树的根节点是什么？上面的每个对象是怎么实例化的？ 为什么都实现了Lifecycle接口？ 要回答这个问题我们可以先来了解下Tomcat 的启动过程。\nTomcat 的启动过程 ![tomcat 启动过程](images/tomcat 启动过程.png)\n上图就是tomcat 启动的过程，Bootstrap 为tomcat 的启动类，分为init, load, start 大的三步，然后又分别调用Catalina 对应的load 和start 方法，在启动过程中逐步实例化各个组件并构建以Catalina为根节点的对象树。\n同时我们发现启动过程中\u0026quot;init\u0026quot;,\u0026ldquo;start\u0026rdquo; 这类方法随处可见，这不难理解层次架构中每个组件都有自己的生命周期，因此他们都实现了LifeCycle 接口，通过这个接口来管理所有组件的生命周期。同时，由于树形结构的存在，我们就可以做到一键启停，比如server 的start 方法会调用子节点的方法。\n同时，我们可以看到Lifecycle中还枚举了LifecycleState，各个组件在生命周期中的每一个阶段都有一个对应的状态和事件，同时还有维护的LifecycleListener，通过事件监听的机制可以很方便扩展各个组件现有的生命周期方法。\n常见的LifeCycleListener\nEngineConfig HostConfig ContextConfig \u0026hellip; Tomcat众多组件中有两个核心组件：连接器(Connector) 和容器(Container).\nConntector 维护在Service 实例中，它的主要功能就是负责对外交流，包括监听端口，接收请求，读取并解析请求数据，然后交给Servlet 处理，并将响应写回给客户端。\nContainer 其实是一个比较业务化的描述，我们常听到\u0026quot;Spring容器\u0026quot;，\u0026ldquo;Servlet容器\u0026rdquo;，那到底什么是容器？容器是用来装东西的，一个水杯也是容器，装的是水。那我们tomcat里说的容器主要目的是为了装Servlet, 这也是它的核心功能之一 —— 加载并管理 Servlet 。我们上面看架构的时候可以发现Engine，Host , Context, Wrapper 都实现了Container 接口，因此他们都可以理解为容器，只不过是一种套娃式设计。\n但是我们有时候也看到说\u0026quot;Catalina 是tomcat 的servlet 容器\u0026quot;, 这种说法正确吗？ 其实也正确，因为catalina 作为对象树的根节点管理着整个下层容器，所以往大了我们也可以说Catalina是容器，往小了说就只有实现了Container接口的组件才是\u0026quot;容器\u0026quot;，容器只是一种大家常用的用来比拟的词，更重要的是明白它背后想表达的是什么。\n请求接收和处理 Connector的职责又可以细分为两部分：网络通信(EndPoint), 根据应用层协议解析请求数据(Processor), 封装ServletRequest交给Servlet 处理(Adaptor)。\n我们在前面demo默认的应用层协议是HTTP/1.1 ，其实tomcat 还支持AJP, HTTP/2\nConnector的创建 在server.xml 中有如下配置，当Digister解析xml文件发现这个配置时就会去实例化Connector.\n\u0026lt;Connector port=\u0026#34;8080\u0026#34; protocol=\u0026#34;HTTP/1.1\u0026#34; connectionTimeout=\u0026#34;20000\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; 而实例化的操作是在开始解析xml之前给Digister添加了对应的Rule决定的。\n// 在开始解析xml文件之前会给Digister添加一个Rule来告诉Digister遇到\u0026lt;Connector\u0026gt;标签时的处理逻辑 digester.addRule(\u0026#34;Server/Service/Connector\u0026#34;, new ConnectorCreateRule()); 然后在实例化Connector的时候会根据我们配置的协议创建ProtocolHandler, 它是Connector中很重要的一个组件，下面会提到。\n而针对HTTP/1.1 会创建Http11NioProtocol\n再来看看这个Http11NioProtocol，\n在创建Http11NioProtocol的时候会传入一个NioEndpoint 作为构造函数的参数，\npublic Http11NioProtocol() { super(new NioEndpoint()); } 而EndPoint维护在AbstractProtocol中，\npublic abstract class AbstractProtocol\u0026lt;S\u0026gt; implements ProtocolHandler, MBeanRegistration { ... /** * Endpoint that provides low-level network I/O - must be matched to the * ProtocolHandler implementation (ProtocolHandler using NIO, requires NIO * Endpoint etc.). */ private final AbstractEndpoint\u0026lt;S,?\u0026gt; endpoint; ... } Connector 创建完后会调用service#addConnector 把它绑定到service, 至此我们的知道了：\nConnector 是在解析xml 时根据事先指定的Rule创建 Connector 包含ProtocolHandler, 在实例化Connector时会根据xml 配置来创建ProtocolHandler, HTTP/1.1 会创建Http11NioProtocol ProtocolHandler中维护着EndPoint 组件，Http11NioProtocol默认创建NioEndpoint 监听网络端口和接收连接请求 Acceptor Acceptor 实现了Runnable 接口，是维护在AbstractEndpoint内部的一个field这个类很简单，主要逻辑就是在run方法中调用endpoint.serverSocketAccept()以及endpoint.setSocketOptions(socket)来监听端口和接收请求。\n冷知识：field 和property 的区别是什么？\nfield 没有get/set 方法，不会对外暴露， 反之property需要，所以property通常有get/set 方法\nAcceptor 的创建及启动\ntomcat 启动过程中，在调用catalina 的start 方法后，会依次调用server.start(), service.start()，而在service 组件的startInternal方法中会调用Connectors 的start方法。\npublic class StandardService extends LifecycleMBeanBase implements Service { ... @Override protected void startInternal() throws LifecycleException { ... // Start our defined Connectors second synchronized (connectorsLock) { for (Connector connector: connectors) { // If it has already failed, don\u0026#39;t try and start it if (connector.getState() != LifecycleState.FAILED) { connector.start(); } } } } ... } public class Connector extends LifecycleMBeanBase { ... /** * Coyote protocol handler. */ protected final ProtocolHandler protocolHandler; ... @Override protected void startInternal() throws LifecycleException { ... try { protocolHandler.start(); } catch (Exception e) { throw new LifecycleException( sm.getString(\u0026#34;coyoteConnector.protocolHandlerStartFailed\u0026#34;), e); } } ... } public abstract class AbstractProtocol\u0026lt;S\u0026gt; implements ProtocolHandler, MBeanRegistration { ... @Override public void start() throws Exception { ... endpoint.start(); ... } ... } 最终会调用到EndPoint的startInternal方法\npublic class NioEndpoint extends AbstractJsseEndpoint\u0026lt;NioChannel,SocketChannel\u0026gt; { @Override public void startInternal() throws Exception { if (!running) { running = true; paused = false; ... // Start poller thread poller = new Poller(); Thread pollerThread = new Thread(poller, getName() + \u0026#34;-Poller\u0026#34;); pollerThread.setPriority(threadPriority); pollerThread.setDaemon(true); pollerThread.start(); startAcceptorThread(); } } } public abstract class AbstractEndpoint\u0026lt;S,U\u0026gt; { protected void startAcceptorThread() { acceptor = new Acceptor\u0026lt;\u0026gt;(this); String threadName = getName() + \u0026#34;-Acceptor\u0026#34;; acceptor.setThreadName(threadName); Thread t = new Thread(acceptor, threadName); t.setPriority(getAcceptorThreadPriority()); t.setDaemon(getDaemon()); t.start(); } } Acceptor线程启动后\n// Acceptor 类 @Override public void run() { ... while (!stopCalled) { socket = endpoint.serverSocketAccept(); ... if (!stopCalled \u0026amp;\u0026amp; !endpoint.isPaused()) { if (!endpoint.setSocketOptions(socket)) { endpoint.closeSocket(socket); } } else { endpoint.destroySocket(socket); } ... } .... } //NioEndpoint类 @Override protected SocketChannel serverSocketAccept() throws Exception { // serverSocketChannel 是在catalina load 阶段通过初始化 // 如果设置了blocking 所以此处会阻塞，例如 serverSocketChannel.configureBlocking(true)，否则立即返回 SocketChannel result = serverSocketChannel.accept(); ... return result; } @Override protected boolean setSocketOptions(SocketChannel socket) { NioSocketWrapper socketWrapper = null; try { // 分配NioChannel NioChannel channel = null; if (nioChannels != null) { channel = nioChannels.pop(); } if (channel == null) { SocketBufferHandler bufhandler = new SocketBufferHandler( socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); if (isSSLEnabled()) { channel = new SecureNioChannel(bufhandler, this); } else { channel = new NioChannel(bufhandler); } } //封装SocketWrapper NioSocketWrapper newWrapper = new NioSocketWrapper(channel, this); channel.reset(socket, newWrapper); connections.put(socket, newWrapper); socketWrapper = newWrapper; // Set socket properties // Disable blocking, polling will be used socket.configureBlocking(false); if (getUnixDomainSocketPath() == null) { socketProperties.setProperties(socket.socket()); } socketWrapper.setReadTimeout(getConnectionTimeout()); socketWrapper.setWriteTimeout(getConnectionTimeout()); socketWrapper.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); // 将socketWrapper交给poller poller.register(socketWrapper); return true; } catch (Throwable t) { ExceptionUtils.handleThrowable(t); try { log.error(sm.getString(\u0026#34;endpoint.socketOptionsError\u0026#34;), t); } catch (Throwable tt) { ExceptionUtils.handleThrowable(tt); } if (socketWrapper == null) { destroySocket(socket); } } // Tell to close the socket if needed return false; } // Poller类 public void register(final NioSocketWrapper socketWrapper) { socketWrapper.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. PollerEvent pollerEvent = createPollerEvent(socketWrapper, OP_REGISTER); addEvent(pollerEvent); } 小结\n在tomcat start阶段会在Endpoint start 的时候创建唯一一个acceptor 线程\nAcceptor线程通过死循环来调用endpoint.serverSocketAccept() 最终调用serverSocketChannel.accept()来接受新的连接，有新连接时会返回一个SocketChannel。这里和我们前面demo代码中的实现有个不同之处是前面demo代码中用的是BIO模式，而从tomcat 8.0开始默认NIO，这是NIO的实现方式。\n然后调用endpoint.setSocketOptions(socket),来封装SocketWrapper，并调用poller.register(socketWrapper)，创建PollerEvent， 并维护在Poller 内部的events 同步队列中。\n我们再来看看Poller 是做什么的。\nPoller Poller 线程也是在Endpoint start的时候创建，内部维护着一个events 队列。\nevents 队列\nevents 队列是一个先进先出的队列，当acceptor 接收到新的请求连接后会封装PollerEvent 添加到这个队列中， 每个Poller Event 包含这个链接的socketWrapper, socketWrapper 中包含可以用来读写数据的SocketChannel.\nrun方法\nrun方法会不断去遍历events 队列， 如果有event 就会从队列中取出来消费\n/** * The background thread that adds sockets to the Poller, checks the * poller for triggered events and hands the associated socket off to an * appropriate processor as events occur. */ @Override public void run() { // Loop until destroy() is called while (true) { boolean hasEvents = false; try { if (!close) { hasEvents = events(); if (wakeupCounter.getAndSet(-1) \u0026gt; 0) { // If we are here, means we have other stuff to do // Do a non blocking select keyCount = selector.selectNow(); } else { keyCount = selector.select(selectorTimeout); } wakeupCounter.set(0); } ... } catch (Throwable x) { ExceptionUtils.handleThrowable(x); log.error(sm.getString(\u0026#34;endpoint.nio.selectorLoopError\u0026#34;), x); continue; } Iterator\u0026lt;SelectionKey\u0026gt; iterator = keyCount \u0026gt; 0 ? selector.selectedKeys().iterator() : null; // Walk through the collection of ready keys and dispatch // any active event. while (iterator != null \u0026amp;\u0026amp; iterator.hasNext()) { SelectionKey sk = iterator.next(); iterator.remove(); NioSocketWrapper socketWrapper = (NioSocketWrapper) sk.attachment(); // Attachment may be null if another thread has called // cancelledKey() if (socketWrapper != null) { processKey(sk, socketWrapper); } } // Process timeouts timeout(keyCount,hasEvents); } getStopLatch().countDown(); } 解析请求数据 processKey\npoller线程从events 队列中取出事件后会调用processKey(sk, socketWrapper) 进行消费\nprotected void processKey(SelectionKey sk, NioSocketWrapper socketWrapper) { try { if (close) { cancelledKey(sk, socketWrapper); } else if (sk.isValid()) { if (sk.isReadable() || sk.isWritable()) { if (socketWrapper.getSendfileData() != null) { processSendfile(sk, socketWrapper, false); } else { unreg(sk, socketWrapper, sk.readyOps()); boolean closeSocket = false; // Read goes before write if (sk.isReadable()) { if (socketWrapper.readOperation != null) { if (!socketWrapper.readOperation.process()) { closeSocket = true; } } else if (socketWrapper.readBlocking) { synchronized (socketWrapper.readLock) { socketWrapper.readBlocking = false; socketWrapper.readLock.notify(); } } else if (!processSocket(socketWrapper, SocketEvent.OPEN_READ, true)) { closeSocket = true; } } if (!closeSocket \u0026amp;\u0026amp; sk.isWritable()) { if (socketWrapper.writeOperation != null) { if (!socketWrapper.writeOperation.process()) { closeSocket = true; } } else if (socketWrapper.writeBlocking) { synchronized (socketWrapper.writeLock) { socketWrapper.writeBlocking = false; socketWrapper.writeLock.notify(); } } else if (!processSocket(socketWrapper, SocketEvent.OPEN_WRITE, true)) { closeSocket = true; } } if (closeSocket) { cancelledKey(sk, socketWrapper); } } } } else { // Invalid key cancelledKey(sk, socketWrapper); } } catch (CancelledKeyException ckx) { cancelledKey(sk, socketWrapper); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); log.error(sm.getString(\u0026#34;endpoint.nio.keyProcessingError\u0026#34;), t); } } processSocket\nprocessSocket的实现在AbstractEndpoint 中，可以看到创建了SocketProcessor并交给线程池来处理。划重点：每一个socket 都会有一个对应的socketProcessor来处理。\npublic boolean processSocket(SocketWrapperBase\u0026lt;S\u0026gt; socketWrapper, SocketEvent event, boolean dispatch) { try { ... // 创建SocketProcessor， SocketProcessor是EndPoint 的内部类 sc = createSocketProcessor(socketWrapper, event); ... Executor executor = getExecutor(); // 交给线程池来处理 executor.execute(sc); ... } catch (RejectedExecutionException ree) { getLog().warn(sm.getString(\u0026#34;endpoint.executor.fail\u0026#34;, socketWrapper) , ree); return false; } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This means we got an OOM or similar creating a thread, or that // the pool and its queue are full getLog().error(sm.getString(\u0026#34;endpoint.process.fail\u0026#34;), t); return false; } return true; } SocketProcessor是EndPoint 的内部类，最终会调用doRun 方法来处理\n@Override protected void doRun() { Poller poller = NioEndpoint.this.poller; ... // getHandler 返回的就是ConnectionHandler， 是AbstractProtocol的一个内部类 state = getHandler().process(socketWrapper, event); ... } 返回的就是ConnectionHandler的process 方法，\n@Override public SocketState process(SocketWrapperBase\u0026lt;S\u0026gt; wrapper, SocketEvent status) { ... try { ... if (processor == null) { processor = recycledProcessors.pop(); ... } if (processor == null) { // 返回Processor processor = getProtocol().createProcessor(); register(processor); ... } ... do { state = processor.process(wrapper, status); ... } while ( state == SocketState.UPGRADING); ... return state; } catch(Exception e){} // Make sure socket/processor is removed from the list of current // connections release(processor); return SocketState.CLOSED; } // AbstactHttp11Protocol 中createProcessor 的实现 // 注意此处传入了一个Adapter, 它在Connector初始化时创建 // adapter = new CoyoteAdapter(this); // protocolHandler.setAdapter(adapter); @Override protected Processor createProcessor() { Http11Processor processor = new Http11Processor(this, adapter); return processor; } 以HTTP/1.1 为例， 上述代码会创建HTTP11Processor 来处理这个socket\nAbstractProcessorLight的process 方法。\n@Override public SocketState process(SocketWrapperBase\u0026lt;?\u0026gt; socketWrapper, SocketEvent status) throws IOException { ... do { ... if(condition) // service 是抽象方法 state = service(socketWrapper); } ... } while (state == SocketState.ASYNC_END || dispatches != null \u0026amp;\u0026amp; state != SocketState.CLOSED); return state; } 小结\n每一个Http11Processor 内部会维护一个Http11InputBuffer 和一个Http11OutputBuffer, 用作针对socket IO 的缓存层，在实现的service 方法中来解析请求行，请求头, 然后将请求交给Adapter处理\nHttp11Processor的service 方法\n@Override public SocketState service(SocketWrapperBase\u0026lt;?\u0026gt; socketWrapper) throws IOException { .... // Parsing the request header if (!inputBuffer.parseRequestLine(keptAlive, protocol.getConnectionTimeout(), protocol.getKeepAliveTimeout())) { if (inputBuffer.getParsingRequestLinePhase() == -1) { return SocketState.UPGRADING; } else if (handleIncompleteRequestLineRead()) { break; } } // Process the Protocol component of the request line // Need to know if this is an HTTP 0.9 request before trying to // parse headers. prepareRequestProtocol(); ... //解析完后会调用adaptor 的service 方法 getAdapter().service(request, response); } 解析请求行 解析请求行的操作在Http11InputBuffer的parseRequestLine中进行，\nparseRequestLine会调用私有方法fill(boolean block) ,来读取原始的请求数据，在这里它就是一个字节数组。\nfill方法中通过nRead = socketWrapper.read(block, byteBuffer); 会将socket 中的输入流读取到Http11InputBuffer中的byteBuffer中\n跳过空行\n解析请求方法： 从第一个字符(Token)开始读，读到空白(\u0026rsquo; \u0026lsquo;) 或tab(\u0026rsquo;\\t\u0026rsquo;) 结束， 这一步结束后可以得到GET， 然后通过request.method().setBytes(byteBuffer.array(), parsingRequestLineStart,pos - parsingRequestLineStart) 来保存请求方法，注意此处保存的是源码全部的字节数组，以及GET在数组中对应的起始位置。\n此处的request是org.apache.coyote.Request, 在Http11Processor实例化的时候构建, 维护在AbstractProcessor 中\n解析URI: 继续往下读字符，直到空白或换行，例如这一步会得到 /my-app/ping 然后类似的通过request.requestURI().setBytes(byteBuffer.array(), parsingRequestLineStart,end - parsingRequestLineStart) 将这部分信息保存在request中，记录URI在数组中起始位置。\n解析协议：继续往下读字符，直到空白或换行，通过request.protocol().setBytes(byteBuffer.array(), parsingRequestLineStart,end - parsingRequestLineStart) 将请求所用的协议例如HTTP保存在request中，记录协议在数组中起始位置。\nrequest中的请求协议，方法，URL等每一个信息都用MessageBytes 类型的变量来存储，MessageBytes 内部维护着一个ByteChunk 字节块，上面解析出来的请求行信息都会变成bytechunk 及MessageByte存储到request中。\n解析请求头 解析请求头通过inputBuffer.parseHeaders() 来进行，也是按照HTTP协议来进行字符的操作判断解析出headers, 然后存储在request 中。\n处理请求 Adapter的创建\n//Adapter 是在connector初始化的时候创建的 @Override protected void initInternal() throws LifecycleException { ... // Initialize adapter adapter = new CoyoteAdapter(this); protocolHandler.setAdapter(adapter); ... try { protocolHandler.init(); } catch (Exception e) { throw new LifecycleException( sm.getString(\u0026#34;coyoteConnector.protocolHandlerInitializationFailed\u0026#34;), e); } } CoyoteAdapter的service 方法，\n@Override public void service(org.apache.coyote.Request req, org.apache.coyote.Response res) throws Exception { ... if (request == null) { // 此处创建的是org.apache.catalina.connector.Request request = connector.createRequest(); request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); // Link objects request.setResponse(response); response.setRequest(request); // Set as notes req.setNote(ADAPTER_NOTES, request); res.setNote(ADAPTER_NOTES, response); // Set query string encoding req.getParameters().setQueryStringCharset(connector.getURICharset()); } ... try { // Parse and set Catalina and configuration specific // request parameters postParseSuccess = postParseRequest(req, request, res, response); if (postParseSuccess) { ... // Calling the container connector.getService().getContainer().getPipeline().getFirst().invoke( request, response); } if (request.isAsync()) { ... } else { request.finishRequest(); response.finishResponse(); } } catch (IOException e) { // Ignore } finally { ... } } 注意此处的一个比较长的链式调用，connector.getService().getContainer().getPipeline().getFirst().invoke(request, response),此处涉及另两个设计，Pipeline 和Valve ，后面补充。\n而默认情况下这里会执行StandardEngineValve的invoke方法\n@Override public final void invoke(Request request, Response response) throws IOException, ServletException { // Select the Host to be used for this Request Host host = request.getHost(); ... // Ask this Host to process this request host.getPipeline().getFirst().invoke(request, response); } 然后Engine依旧通过类似的Pipeline 做法把请求交给Host处理，那么依次类推，一定会执行到StandardHostValve的invoke 方法 中去，然后StandardContextValve -\u0026gt; StandardWrapperValve, 前面说到Wrapper相当于Servlet, 我们看看StandardWrapperValve中的实现，\n@Override public final void invoke(Request request, Response response) throws IOException, ServletException { ... Servlet servlet = null; ... servlet = wrapper.allocate(); ... // Create the filter chain for this request // 大名鼎鼎的Tomcat Filter 接口 ApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet); ... filterChain.doFilter(request.getRequest(), response.getResponse()); ... } 这里关键步骤看到 filterChain.doFilter(request.getRequest(), response.getResponse());就结束了，再来看ApplicationFilterChain的doFilter方法，\n@Override public void doFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException { if( Globals.IS_SECURITY_ENABLED ) { ... } else { internalDoFilter(request,response); } } private void internalDoFilter(ServletRequest request,ServletResponse response) throws IOException, ServletException { // Call the next filter if there is one if (pos \u0026lt; n) { ApplicationFilterConfig filterConfig = filters[pos++]; try { Filter filter = filterConfig.getFilter(); ... if( Globals.IS_SECURITY_ENABLED ) { ... } else { // 运行tomcat 过滤器 filter.doFilter(request, response, this); } } catch (Exception){ ... } return; } // We fell off the end of the chain -- call the servlet instance try { ... servlet.service(request, response); ... } catch (Exception){ ... } } 可以看到终于在ApplicationFilterChain中调用了servlet.service(request, response) !!!!!\n小结 Connector 中有一个属性叫protocolHandler， connector运行start方法后, 会运行protocolHandler.start()\nprotocolHandler继承AbstractProtocol, AbstractProtocol中有个属性叫endpoint， 会在prorocolHandler实例化的时候实例化EndPoint\nAbstractProtocol的start方法，会执行endpoint的start方法\nendpoint start 方法中会分别开启两个线程(以下基于NioEndPoint类的分析)\nPoller 线程， 用来消费和处理请求， Poller 是NioEndPoint的内部类 Acceptor线程，用来监听端口和接收socket链接 Acceptor线程run 方法\n在循环会调用endpoint 的serverSocketAccept方法来最终执行ServerSocketChannel.accpet()方法，请求到来后会返回一个SocketChannel 会调用endpoint.setSocketOptions(socket)方法来封装sockerwrapper, 并向Poller注册socketWrapper 注册socketWrapper的时候会创建PollerEvent 并维护在Poller内部的events队列中 Poller线程run 方法\n循环中不断遍历events队列，如果有事件则取出socket处理，有个核心方法是调用AbstractEndpoint的processSocket方法 AbstractEndpoint的processSocket中会创建SocketProcessor线程并交给线程池去运行，SocketProcessor是EndPoint 子类中的内部类 SocketProcessor线程doRun 方法(run 方法由父类覆写然后调用子类的doRun方法)\n调用ConnectionHandler 的process 方法，ConnectionHandler是AbstractProtocol的内部类 ConnectionHandler process 方法中会调用Processor方法process方法来处理，例如Http11Processor Http11Processor继承AbstractProcessorLight，AbstractProcessorLight会调用子类的service方法 然后Http11Processor会解析请求行，请求头，做一些预处理构建coyote的Request 和Response，然后通过调用getAdapter().service(request, response)将请求交给Adapter处理 Adapter的service 方法\n构建org.apache.catalina.connector.Request 和org.apache.catalina.connector.Response，他们实现了HttpServletRequest和HttpServletResponse, 所以这里本质上是构建ServletRequest 和ServletResponse\n然后通过Pipeline 将请求交给容器处理, connector.getService().getContainer().getPipeline().getFirst().invoke(request,response)\n首先会调用StandardEngineValve的invoke方法，然后依次调用StandardHostValve、StandardContextValve、StandardWrapperValve\nStandardWrapperValve的invoke 中会获取servlet, 然后创建ApplicationFilterChain，调用filterChain.doFilter方法\n然后执行tomcat 的过滤器链，最终执行servlet.service(request, response)方法\n还有一些疑问，比如：\nServlet 是什么时候被加载的，它的生命周期是什么时候结束的？ 处理请求的servlet是如何被定位到的？ Servlet 处理完请求后tomcat如何将返回数据响应给客户端？ Servlet 和请求的Mapping 一个请求的格式其实包括ip,port, path, 那么映射到tomcat 结构上来其实就是要找到对应的Host, Context, Wrapper(serlvelt).\n我们在StandardEngineValve 的invoke 方法中发现它是直接通过Host host = request.getHost(); 来定位到host的，host维护在org.apache.catalina.connector.Request内部的MappingData中，而这个MappingData还包含Context, Wrapper等信息， 说明这个mapping 工作发生在connector 把请求交给容器处理之前， 所以需要关注MappingData是如何创建的。\nHttp11Processor 交给Adapter的是org.apache.coyote.Request, org.apache.catalina.connector.Request是在Adapter的service 方法中初次构建的。\n在Adapter的postParseRequest 方法中有段关键代码：\nconnector.getService().getMapper().map(serverName, decodedURI, version, request.getMappingData()) Mapper 是Service的组件，在service start的时候会start mapperListener， 然后通过registerHost(host) 将host 封装为MappedHost添加到Mapper 内部维护的hosts 数组中， 同时MappedHost内部维护了ContextList，ContextList 内部维护MappedContext，MappedContext内部维护ContextVersion，ContextVersion内部维护MappedWrapper， 由此又构建了一套层级关系。\nMappingData就是在这里初始化的。通过查找Mapper 内部维护的hosts定位到Host 后就可以再定位Context, 最终定位到wrapper. 在处理请求的时候直接就可以通过request.getHost()、request.getContext();、request.getWrapper();找到对应的容器组件的pipeline去处理请求。\n/** * 参数示例： map(\u0026#34;localhost\u0026#34;,\u0026#34;/my-app/ping\u0026#34;, null, mappingData) */ public void map(MessageBytes host, MessageBytes uri, String version, MappingData mappingData) throws IOException { if (host.isNull()) { String defaultHostName = this.defaultHostName; if (defaultHostName == null) { return; } host.getCharChunk().append(defaultHostName); } host.toChars(); uri.toChars(); internalMap(host.getCharChunk(), uri.getCharChunk(), version, mappingData); } // 重点是这个internalMap方法 private final void internalMap(CharChunk host, CharChunk uri, String version, MappingData mappingData) throws IOException { ... // Virtual host mapping MappedHost[] hosts = this.hosts; MappedHost mappedHost = exactFindIgnoreCase(hosts, host); mappingData.host = mappedHost.object; ... // Context mapping ContextList contextList = mappedHost.contextList; MappedContext[] contexts = contextList.contexts; int pos = find(contexts, uri); ... ContextVersion contextVersion = null; ContextVersion[] contextVersions = context.versions; final int versionCount = contextVersions.length; if (versionCount \u0026gt; 1) { Context[] contextObjects = new Context[contextVersions.length]; for (int i = 0; i \u0026lt; contextObjects.length; i++) { contextObjects[i] = contextVersions[i].object; } mappingData.contexts = contextObjects; if (version != null) { contextVersion = exactFind(contextVersions, version); } } if (contextVersion == null) { // Return the latest version // The versions array is known to contain at least one element contextVersion = contextVersions[versionCount - 1]; } mappingData.context = contextVersion.object; mappingData.contextSlashCount = contextVersion.slashCount; // Wrapper mapping if (!contextVersion.isPaused()) { internalMapWrapper(contextVersion, uri, mappingData); } } 响应过程 在最简tomcat一节中我们知道其实响应就是向socket对象的outputStream中写入数据，而tomcat将请求交给servlet处理时是将封装好的ServletRequest 和 ServletResponse的都交给了servlet的。\nservlet.service(request, response); 看下面这个简单的Servlet, 以这个servlet为例我们看看HTTP响应是怎么进行的\npublic class SampleServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { response.getWriter().write(\u0026#34;Pong!\u0026#34;); } } 通过response.getWriter().write(\u0026quot;Pong!\u0026quot;); 来响应，响应完后我们就可以在浏览器中看到\u0026quot;Pong!\u0026quot;.\n​\n可以看到写入响应时会先写入缓存中，最后统一将缓存数据刷新到socket中。\nPipeline 和 Valve pipeline 是ContainerBase 抽象类中的一个属性, 具体实例化了一个StandardPipeline，并通过Container 接口暴露了getPipeline方法，所以Engine, Context, Host, Wrapper等组件都会有这个属性。而pipeline中维护的是一系列的Valve。\nPipeline public interface Pipeline extends Contained { public Valve getBasic(); public void setBasic(Valve valve); public void addValve(Valve valve); public Valve[] getValves(); public void removeValve(Valve valve); public Valve getFirst(); public boolean isAsyncSupported(); public void findNonAsyncValves(Set\u0026lt;String\u0026gt; result); } Valve Valve是一个类似单向链表的结构，可以通过getNext 找到下一个Valve, 并且有一个核心方法invoke(Request request, Response response)\npublic interface Valve { public Valve getNext(); public void setNext(Valve valve); public void backgroundProcess(); public void invoke(Request request, Response response) throws IOException, ServletException; public boolean isAsyncSupported(); } 这时候再来回顾connector.getService().getContainer().getPipeline().getFirst().invoke(request,response)这段Adapter的service 方法将请求交给容器处理的代码，就能明白了.\npublic class StandardPipeline extends LifecycleBase implements Pipeline { ... //调用getFirst 的时候，如果有first就返回否则返回basic @Override public Valve getFirst() { if (first != null) { return first; } return basic; } ... } Valve是怎么添加的 StandardEngine\nStandardHost\n构造函数中也是默认设置了一个basic valve, 我们还可以通过web.xml 来配置，这其实是tomcat 留给我们的扩展点。\n那对于Host而言这两个valve的顺序是什么呢？\n首先肯定是执行Host组件的构造函数，所以会先设置basic valve, 然后解析到\u0026lt;Valve\u0026gt; 标签会根据配置的digister SetNextRule 来调用addValve.\n@Override public void addValve(Valve valve) { ... if (first == null) { first = valve; valve.setNext(basic); } else { Valve current = first; while (current != null) { if (current.getNext() == basic) { current.setNext(valve); valve.setNext(basic); break; } current = current.getNext(); } } ... } 可以看到如果pipeline 中first为null, 则server.xml 中配置的第一个valve就是first, 如果first不为空，就把这个valve 作为first 的下一个节点， basic 永远是链表中最后一个节点。\nStandardContext\nStandardWrapper\n小结\nEngine/Host/Context/Wrapper 组件在初始化的构造方法中会设置basic valve 我们可以通过配置文件的方式添加其他valve, 添加的第一个valve 会作为first value, 依次构建一个链表，basic valve会作为链表上最后一个节点 Valve 什么时候会运行 请求到达容器之前会由Adapter的service 方法将请求交给容器，关键方法是connector.getService().getContainer().getPipeline().getFirst().invoke(request,response) 此时会调用Engine 的first valve的invoke 方法, 如果没有first 则调用 basic value. 当某一层容器的pipeline 中有多个valve时，在一个valve执行的最后会通过getNext().invoke(request, response);调用下一个Valve, 直到最后调用到basic valve basic valve是valve 链中最后一个节点(最后执行），这时上层容器又会调用下一层容器的pipeline 中的valve 的invoke 方法，依次类推 Tomcat的类加载机制 在请求处理过程的分析中，我们提到最后tomcat会将请求交给servlet来处理，但servlet是什么时候被加载和初始化的呢？\n可能最快想到的是利用类加载器去加载webapp 各个应用下面的classes 文件，把他们变成可执行的对象，但是倘若不同的应用下面假如都有一个MyApp 类，类名相同但是实现不同，tomcat本身是一个java进程，根据Jdk的双亲委派模型，如果不做处理当尝试去加载第二个MyApp 的时候会复用之前已经加载好的MyApp(为什么?), 从而导致行为和预期的不一致，所以tomcat 为了隔离各个应用，会打破这个双亲委派模型。\nJDK类加载器与双亲委派模型 什么是类加载器？ 说白了，我们写的代码是存在以java 为后缀的文件中，然后JDK通过编译器将java 文件编译成class文件，也就是字节码文件，但字节码是一种不能由硬件直接执行的中间代码，只能被JVM装载并解释执行，然后类加载器的作用就是把这些这些字节码加载到内存中并在内存中生成一个代表该类的Class对象， 最后由执行器把它翻译成机器码然后交给机器执行。\nJava虚拟机定义了三种类加载器：\n启动类加载器（Bootstrap Class Loader）： 通常由本地代码实现，也称为根类加载器，它负责加载%JAVA_HOME%/lib路径下Java虚拟机的核心类库 扩展类加载器（Extension Class Loader）：它是用来加载Java扩展类库的类加载器。扩展类库包括javax和java.util等包，它们位于jre/lib/ext目录下 应用程序类加载器（Application Class Loader）：也称为系统类加载器，它负责加载%CLASSPATH%路径下应用程序的类。 我们在启动java进程的时候通常需要传递一个classpath 参数，例如通过IDEA 源码启动tomcat时可以在控制台看到启动命令如下：\n/Users/hf/Documents/developer/jdk/zulu21.30.15-ca-jdk21.0.1-macosx_aarch64/bin/java -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:64807,suspend=y,server=n -Dcatalina.home=/Users/hf/IdeaProjects/tomcat/output/build/ -Dcatalina.base=/Users/hf/IdeaProjects/tomcat/output/build/ -javaagent:/Users/hf/Library/Caches/JetBrains/IntelliJIdea2024.1/captureAgent/debugger-agent.jar -Dfile.encoding=UTF-8 -Dsun.stdout.encoding=UTF-8 -Dsun.stderr.encoding=UTF-8 -classpath /Users/hf/IdeaProjects/tomcat/.idea/output/production/tomcat:/opt/homebrew/Cellar/ant/1.10.14/libexec/lib/ant.jar ... org.apache.catalina.startup.Bootstrap 可以看到传递了classpath参数，不传递则默认当前目录。我们自己写的java代码通常由App class loader 来加载。\ntry { Class\u0026lt;?\u0026gt; loadedClass = ClassLoader.getSystemClassLoader().loadClass(\u0026#34;org.apache.catalina.startup.MyClass\u0026#34;); MyClass object = (MyClass) loadedClass.getDeclaredConstructor().newInstance(); object.hi(); } catch (ClassNotFoundException | NoSuchMethodException | InstantiationException | IllegalAccessException | InvocationTargetException e) { throw new RuntimeException(e); } ... class MyClass { public void hi() { System.out.println(\u0026#34;Hello, class loader!\u0026#34;); } } 自定义类加载器 自定义的类加载器必须继承java.lang.ClassLoader, 并覆写findClass方法，findClass 方法会被loadClass调用，下面是Classloader类中loadClass 方法\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats PerfCounter.getParentDelegationTime().addTime(t1 - t0); PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 可以看到基本流程就是:\n查看某个类是否已经被加载，会通过调用native 方法findLoadedClass0，如果已经加载就返回 如果没被加载就先尝试用父类加载器(Extention class loader)加载 父类加载器还加载不到的话就会调用findClass方法 这和我们所熟知的双亲委派模型的思想是一样的，下面给出一个findClass 的写法示例：\n@Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { // class 文件可以放到任何目录 try (FileInputStream fileInputStream = new FileInputStream( new File(\u0026#34;/Users/hf/IdeaProjects/tomcat/MyClass.class\u0026#34;))) { byte[] bytes = fileInputStream.readAllBytes(); return defineClass(name, bytes, 0, bytes.length); } catch (IOException e) { throw new RuntimeException(e); } } // 测试 @Test public void testClassLoader() { try { MyClassLoader myClassLoader = new MyClassLoader(); Class\u0026lt;?\u0026gt; loadedClass = myClassLoader.loadClass(\u0026#34;MyClass\u0026#34;); Object object = loadedClass.getDeclaredConstructor().newInstance(); Method method = loadedClass.getMethod(\u0026#34;hi\u0026#34;); method.invoke(object,null); } catch (ClassNotFoundException | NoSuchMethodException | InstantiationException | IllegalAccessException | InvocationTargetException e) { throw new RuntimeException(e); } } Tomcat的类加载器 Tomcat 拥有不同的自定义类加载器，以实现对各种资源库的控制。一般来说，Tomcat 主要用类加载器解决以下 4 个问题。\n各个Web应用之间各自使用的Java类库要互相隔离 \u0026mdash; WebappClassLoader。\n各个Web应用之间可以提供共享的Java类库 \u0026mdash; SharedClassLoader。\nTomcat本身的类和Web应用的类要互相隔离 \u0026mdash; CatalinaClassLoader。\nWebappClassLoaderBase的start方法的源代码中并没有看到我们以为的findClass 或loadClass 操作，那加载servlet是什么时候进行的？\n// WebappClassLoaderBase的start方法 @Override public void start() throws LifecycleException { state = LifecycleState.STARTING_PREP; WebResource[] classesResources = resources.getResources(\u0026#34;/WEB-INF/classes\u0026#34;); for (WebResource classes : classesResources) { if (classes.isDirectory() \u0026amp;\u0026amp; classes.canRead()) { localRepositories.add(classes.getURL()); } } WebResource[] jars = resources.listResources(\u0026#34;/WEB-INF/lib\u0026#34;); for (WebResource jar : jars) { if (jar.getName().endsWith(\u0026#34;.jar\u0026#34;) \u0026amp;\u0026amp; jar.isFile() \u0026amp;\u0026amp; jar.canRead()) { localRepositories.add(jar.getURL()); jarModificationTimes.put( jar.getName(), Long.valueOf(jar.getLastModified())); } } state = LifecycleState.STARTED; } 答案是有两次。\n第一次通过LifeCycleEvent处理注解时加载的。\nStandardContext#startInternal -\u0026gt; fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null) -\u0026gt; ContextConfig#lifecycleEvent -\u0026gt; configureStart -\u0026gt; applicationAnnotationsConfig -\u0026gt; WebAnnotationSet.loadApplicationAnnotations(context) -\u0026gt; WebAnnotationSet#loadApplicationServletAnnotations -\u0026gt; Introspection.loadClass(context, wrapper.getServletClass()) -\u0026gt; cl.loadClass(className)\n第二次是请求到来时去尝试加载并实例化Servlet, 第一次如果已经加载了class则会复用。\nStandardWrapper#invoke -\u0026gt; StandardWrapper#allocate -\u0026gt; StandardWrapper#loadServlet -\u0026gt; InstanceManager.newInstance(servletClass) -\u0026gt; DefaultInstanceManager#newInstance -\u0026gt; classLoader.loadClass(className)\nTomcat 是如何打破双亲委派模型的？ 了解这个问题需要看WebappClassLoaderBase的源码，重点是findClass 方法和loadClass 方法\nloadClass\n@Override public Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (JreCompat.isGraalAvailable() ? this : getClassLoadingLock(name)) { .. Class\u0026lt;?\u0026gt; clazz = null; ... // (0) Check our previously loaded local class cache，检查tomcat自己的缓存 clazz = findLoadedClass0(name); if (clazz != null) { ... return clazz; } // (0.1) Check our previously loaded class cache, 检查jvm的缓存 clazz = JreCompat.isGraalAvailable() ? null : findLoadedClass(name); if (clazz != null) { ... return clazz; } // (0.2) Try loading the class with the bootstrap class loader, to prevent // the webapp from overriding Java SE classes. This implements // SRV.10.7.2， 防止覆盖系统的核心类 String resourceName = binaryNameToPath(name, false); ClassLoader javaseLoader = getJavaseClassLoader(); boolean tryLoadingFromJavaseLoader; .... if (tryLoadingFromJavaseLoader) { clazz = javaseLoader.loadClass(name); if (clazz != null) { ... return clazz; } } // (0.5) Permission to access this class when using a SecurityManager ... boolean delegateLoad = delegate || filter(name, true); // (1) Delegate to our parent if requested, 如果配置了用父加载器加载就用父加载器，默认false if (delegateLoad) { ... clazz = Class.forName(name, false, parent); if (clazz != null) { .. return clazz; } } // (2) Search local repositories if (log.isDebugEnabled()) { log.debug(\u0026#34; Searching local repositories\u0026#34;); } try { clazz = findClass(name); if (clazz != null) { ... return clazz; } } catch (ClassNotFoundException e) { // Ignore } // (3) Delegate to parent unconditionally, 如果不使用父加载器，但自己又没有找到就还是用父加载器找一遍 if (!delegateLoad) { ... clazz = Class.forName(name, false, parent); if (clazz != null) { ... return clazz; } ... } } throw new ClassNotFoundException(name); } findClass\n@Override public Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { ... // (1) Permission to define this class when using a SecurityManager .. // Ask our superclass to locate this class, if possible // (throws ClassNotFoundException if it is not found) Class\u0026lt;?\u0026gt; clazz = null; try { ... try { if (securityManager != null) { ... } else { clazz = findClassInternal(name); } } catch(AccessControlException ace) { ... } catch (RuntimeException e) { ... } if ((clazz == null) \u0026amp;\u0026amp; hasExternalRepositories) { try { clazz = super.findClass(name); } catch(AccessControlException ace) { ... } catch (RuntimeException e) { ... } } if (clazz == null) { throw new ClassNotFoundException(name); } } catch (ClassNotFoundException e) { throw e; } // Return the class we have located ... return clazz; } findClassInternal\nprotected Class\u0026lt;?\u0026gt; findClassInternal(String name) { ... String path = binaryNameToPath(name, true); ResourceEntry entry = resourceEntries.get(path); ... Class\u0026lt;?\u0026gt; clazz = entry.loadedClass; if (clazz != null) { return clazz; } synchronized (JreCompat.isGraalAvailable() ? this : getClassLoadingLock(name)) { clazz = entry.loadedClass; ... byte[] binaryContent = resource.getContent(); ... try { // 调用jdk的API去加载类 clazz = defineClass(name, binaryContent, 0, binaryContent.length, new CodeSource(codeBase, certificates)); } catch (UnsupportedClassVersionError ucve) { ... } entry.loadedClass = clazz; } return clazz; } 小结\n先在本地tomcat缓存中查找该类是否已经加载过，如果加载过就返回缓存中的。 如果本地缓存没有就去JVM中查找是否已经加载过，有就返回。 如果缓存里都没有，委托给 bootstrap class loader去加载，防止覆盖系统的核心类库。 如果还没加载到说明不核心库中没有这个类，那就WebappClassLoaderBase自己去加载，调用findClass方法。 findClass 中最终会通过调用findClassInternal来加载，找不到会再次常用用父类加载器来加载。 findClassInternal优先从resourceEntries缓存中查找，找到则返回。 找不到则最终通过class 的binaryContent和调用JDK 的API defineClass 来加载。 经过以上分析我们可以从一个HTTP请求出发初步了解到Tomcat整体的架构设计，以及接收请求、解析请求，加载运行servlet, 到生成响应的全流程，但是tomcat 经过二十年余年的发展，所要处理的业务场景远不止这些，有很多其他的设计和实现值得我们去进一步探索，比如：\ntomcat中关于长链接的处理 分块传输 tomcat是如何对响应进行压缩的(例如gzip)？ \u0026hellip; 这几个问题暂时不作为这次的故事主线，对响应压缩和分块传输感兴趣的同学可以参考我的另一篇：tomcat http 压缩与分块传输原理\n但是在此之前，站在开发者的角度考虑到我们基于springboot开发的时候，我们还有一点没有搞清楚，tomcat 是如何与Springboot联系在一起的呢？\nTomcat 和Springboot 以这个简单的springboot应用(Springboot 3.2.3, 注意老版本会略微有所不同，但大同小异)为例,\ngradle\n... implementation(\u0026#34;org.springframework.boot:spring-boot-starter-web\u0026#34;) ... 这个依赖里引入了spring-boot-starter-tomcat依赖,\n因为用了api 所以在我们的springboot应用中可以访问到spring-boot-starter-tomcat依赖\nspring-boot-starter-tomcat\n引入了tomcat-embed-core 依赖,\n而tomcat-embed-core也就是我们最终会用到的一个核心的tomcat的jar依赖。而在这个jar包里我们可以看到tomcat 的源码。\nPingContoller\n@RestController @RequestMapping(\u0026#34;/ping\u0026#34;) class PingController { @GetMapping fun ping(): String { return \u0026#34;Pong!\u0026#34; } } Springboot应用启动入口也是一个Main方法，详细的Springboot启动过程不在本文的范围内，此处直接跳到tomcat启动的代码。\nSpringApplication#run —\u0026gt; SpringApplication#refreshContext —\u0026gt; ServletWebServerApplicationContext#onRefresh —\u0026gt; ServletWebServerApplicationContext#createWebServer\nprivate void createWebServer() { WebServer webServer = this.webServer; ServletContext servletContext = getServletContext(); if (webServer == null \u0026amp;\u0026amp; servletContext == null) { StartupStep createWebServer = getApplicationStartup().start(\u0026#34;spring.boot.webserver.create\u0026#34;); ServletWebServerFactory factory = getWebServerFactory(); createWebServer.tag(\u0026#34;factory\u0026#34;, factory.getClass().toString()); this.webServer = factory.getWebServer(getSelfInitializer()); ... } else if (servletContext != null) { ... } initPropertySources(); } 上述代码第6行getWebServerFactory(); 返回的是TomcatServletWebServerFactory\n为什么是Tomcat而不是Jetty？\n因为在ServletWebServerFactoryAutoConfiguration 自动装配类中通过@Import 导入了ServletWebServerFactoryConfiguration类下面的几个配置，\n而在ServletWebServerFactoryConfiguration中，通过ConditionalOnClass 注解会默认加载TomcatServletWebServerFactory。\nweb starter 默认集成tomcat, 可以发现Jetty的两个类默认情况下找不到。\n下面再看factory#getWebServer的实现\n@Override public WebServer getWebServer(ServletContextInitializer... initializers) { if (this.disableMBeanRegistry) { Registry.disableRegistry(); } Tomcat tomcat = new Tomcat(); File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(\u0026#34;tomcat\u0026#34;); tomcat.setBaseDir(baseDir.getAbsolutePath()); for (LifecycleListener listener : this.serverLifecycleListeners) { tomcat.getServer().addLifecycleListener(listener); } Connector connector = new Connector(this.protocol); connector.setThrowOnFailure(true); //创建server, service, 并完成connector 和 service的绑定 tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); // 这一步会根据我们application.yml 配置文件中的配置对tomcat server做定制化的配置。 configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) { tomcat.getService().addConnector(additionalConnector); } prepareContext(tomcat.getHost(), initializers); return getTomcatWebServer(tomcat); } 这时除了Tomcat 类外，我们可以看到Connector, Service, Host，Protocol等熟悉的字眼。\nConnector的创建\nConnector connector = new Connector(this.protocol); Server和Service的创建\n在tomcat.getService()实现中，可以看到新建了StandardServer和StandardService并实现了双向绑定。\npublic Service getService() { return getServer().findServices()[0]; } public Server getServer() { if (server != null) { return server; } System.setProperty(\u0026#34;catalina.useNaming\u0026#34;, \u0026#34;false\u0026#34;); // 熟悉的StandardServer server = new StandardServer(); initBaseDir(); // Set configuration source ConfigFileLoader.setSource(new CatalinaBaseConfigurationSource(new File(basedir), null)); server.setPort(-1); // 熟悉的StandardService Service service = new StandardService(); service.setName(\u0026#34;Tomcat\u0026#34;); server.addService(service); return server; } Engine和Host的创建\n在tomcat.getHost()的实现中，创建了StandardEngine和StandardHost，并完成了Engine, Host, Service 之间的绑定\npublic Host getHost() { Engine engine = getEngine(); if (engine.findChildren().length \u0026gt; 0) { return (Host) engine.findChildren()[0]; } Host host = new StandardHost(); host.setName(hostname); getEngine().addChild(host); return host; } public Engine getEngine() { Service service = getServer().findServices()[0]; if (service.getContainer() != null) { return service.getContainer(); } Engine engine = new StandardEngine(); engine.setName(\u0026#34;Tomcat\u0026#34;); engine.setDefaultHost(hostname); engine.setRealm(createDefaultRealm()); service.setContainer(engine); return engine; } 至此, 还差一个Wrapper就完成了以Tomcat为根节点的这个层级关系的构建。 Wrapper 是在\nTomcat的启动\n在getWebServer最后一步getTomcatWebServer(tomcat)中,\n// TomcatServletWebServerFactory#getTomcatWebServer protected TomcatWebServer getTomcatWebServer(Tomcat tomcat) { return new TomcatWebServer(tomcat, getPort() \u0026gt;= 0, getShutdown()); } //TomcatWebServer#TomcatWebServer public TomcatWebServer(Tomcat tomcat, boolean autoStart, Shutdown shutdown) { Assert.notNull(tomcat, \u0026#34;Tomcat Server must not be null\u0026#34;); this.tomcat = tomcat; this.autoStart = autoStart; this.gracefulShutdown = (shutdown == Shutdown.GRACEFUL) ? new GracefulShutdown(tomcat) : null; initialize(); } // TomcatWebServer#initialize private void initialize() throws WebServerException { ... this.tomcat.start(); ... } // Tomcat#start public void start() throws LifecycleException { getServer(); server.start(); } 在server.start() 这一步开始之后就是我们前面分析过的tomcat的启动流程。\nServlet 的加载\n我们知道Springboot 框架就包含spring mvc, 所有请求在到达tomcat后，会交给DispathcerServlet 来处理，DispatcherServlet 会再进一步对请求进行分发，交给各自handler/controller来处理。\n那这个DispatcherServlet是什么时候加载的？\nDispatcherServlet的实例化\n在spring 容器构建DispatcherServletRegistrationBean的时候会发现它依赖DispatcherServlet， 这时候就会去实例化DispatcherServlet。\nWrapper 的创建以及Servlet 和wrapper 的绑定\n在StandaradContext#startInternal 中有一段代码：\nprivate Map\u0026lt;ServletContainerInitializer,Set\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt;\u0026gt; initializers = new LinkedHashMap\u0026lt;\u0026gt;(); ... for (Map.Entry\u0026lt;ServletContainerInitializer,Set\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt;\u0026gt; entry : initializers.entrySet()) { try { entry.getKey().onStartup(entry.getValue(), getServletContext()); } catch (ServletException e) { log.error(sm.getString(\u0026#34;standardContext.sciFail\u0026#34;), e); ok = false; break; } } ServletContainerInitializer是Servlet 3.0 新增的一个接口，主要用于在容器启动阶段通过编程风格注册Filter, Servlet以及Listener，以取代通过web.xml配置注册。容器启动阶段依据java spi获取到所有ServletContainerInitializer的实现类，然后执行其onStartup方法.\n其中就有一个spring实现的TomcatStarter\n而TomcatStarter 又会执行内部维护的initializers的onStartup方法\nfor (ServletContextInitializer initializer : this.initializers) { initializer.onStartup(servletContext); } 这个内部维护的initializers是通过如下方式添加：\nthis.webServer = factory.getWebServer(getSelfInitializer()); —\u0026gt;TomcatServletWebServerFactory#getWebServer —\u0026gt;TomcatServletWebServerFactory#prepareContext —\u0026gt;TomcatServletWebServerFactory#configureContext —\u0026gt;new TomcatStarter(initializers)\n其中getSelfInitializer返回的是一个Lamba表达式：\nprivate org.springframework.boot.web.servlet.ServletContextInitializer getSelfInitializer() { return this::selfInitialize; } private void selfInitialize(ServletContext servletContext) throws ServletException { prepareWebApplicationContext(servletContext); registerApplicationScope(servletContext); WebApplicationContextUtils.registerEnvironmentBeans(getBeanFactory(), servletContext); for (ServletContextInitializer beans : getServletContextInitializerBeans()) { beans.onStartup(servletContext); } } 所以最终会执行到ServletContextInitializerBeans 的onStartup方法，\n其中就有一个DispatcherServletRegistrationBean, 然后通过以下调用链\nbeans.onStartup(servletContext) —\u0026gt; DispatcherServletRegistrationBean#onStartup —\u0026gt; DynamicRegistrationBean#register —\u0026gt; ServletRegistrationBean#addRegistration —\u0026gt; ApplicationContextFacade#addServlet —\u0026gt; ApplicationContext#addServlet —\u0026gt; org.apache.catalina.core.ApplicationContext#addServlet\n在ApplicationContext#addServlet中可以看到会创建wrapper,并绑定StandardContext 和wrapper ，若servlet 不为空则会通过wrapper.setServlet(servlet);来绑定servlet 和 wrapper.\n若servlet 为空，则只会setServletClass，且loadClass , 实例化交给后面的步骤进行。\nprivate ServletRegistration.Dynamic addServlet(String servletName, String servletClass, Servlet servlet, Map\u0026lt;String,String\u0026gt; initParams) throws IllegalStateException { ... Wrapper wrapper = (Wrapper) context.findChild(servletName); // Assume a \u0026#39;complete\u0026#39; ServletRegistration is one that has a class and // a name if (wrapper == null) { wrapper = context.createWrapper(); wrapper.setName(servletName); context.addChild(wrapper); } else { if (wrapper.getName() != null \u0026amp;\u0026amp; wrapper.getServletClass() != null) { if (wrapper.isOverridable()) { wrapper.setOverridable(false); } else { return null; } } } ServletSecurity annotation = null; if (servlet == null) { wrapper.setServletClass(servletClass); Class\u0026lt;?\u0026gt; clazz = Introspection.loadClass(context, servletClass); if (clazz != null) { annotation = clazz.getAnnotation(ServletSecurity.class); } } else { wrapper.setServletClass(servlet.getClass().getName()); wrapper.setServlet(servlet); if (context.wasCreatedDynamicServlet(servlet)) { annotation = servlet.getClass().getAnnotation(ServletSecurity.class); } } if (initParams != null) { for (Map.Entry\u0026lt;String,String\u0026gt; initParam : initParams.entrySet()) { wrapper.addInitParameter(initParam.getKey(), initParam.getValue()); } } ServletRegistration.Dynamic registration = new ApplicationServletRegistration(wrapper, context); if (annotation != null) { registration.setServletSecurity(new ServletSecurityElement(annotation)); } return registration; } 至此，wrapper 也就创建完成，并在tomcat 启动的时候就会实例化出了Servlet。和前面分析的tomcat 架构完美衔接，至于请求到达DispatcherServlet后怎么分发交给controller，那就是另一个topic了。\n复习回顾：这里说的wrapper指的是什么？\n","date":"2024-01-10T11:28:33+08:00","image":"http://localhost:1313/posts/tomcat%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/images/IMG_1890_hufea3e9ca65cfbc42e503dcb755cb462c_15847402_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/posts/tomcat%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/","title":"tomcat架构原理解析"},{"content":"在讨论这个问题之前先抛出一个问题：我们都知道计算机内部都是二进制，那么给定一些文本字符串比如英文单词Good, 我们是怎么知道要把它转化为怎样的二进制的？\n这个问题的答案是字符编码。\n1.什么是字符编码 字符编码用来将人类可读的字符比如英文字母数字以及一些符号映射成一个数值，这个数值称为码位，然后通过一定规则用二进制来表示这个数值，它本质上是人为设计的一种规则或者理解为一种映射关系。理解什么是字符编码很重要，它有两个很重要的核心功能：\n将字符根据规则映射成唯一数值并转化为对应的二进制 将二进制数据根据编码规则翻译成人类可读的字符 这也是计算机世界中的一种基本的思想方法论，类似的，音视频存储在计算机中也都有相应的音视频编码算法将其转化为二进制\n2.有哪些字符编码 不同地区文化中的字符集(数量和种类差异), 他们通常有自己对应的字符编码标准，再加上一些厂商自定义的标准，以及技术迭代过程中的新需求，优化等原因导致字符编码有很多种，此处只列举一些常见的。\nASCII: 最早的字符编码 Unicode: 一个全球性的字符编码标准，为世界上几乎所有的字符提供了唯一的编号 UTF-8: UTF-8是Unicode 的一种实现方式 ISO-8859系列: ISO-8859-1: 涵盖了西欧地区最常用的字符 ISO-8859-2: 设计用于中欧地区，涵盖了一些中欧国家的字符需求 ISO-8859-3: 主要设计用于支持南欧、南东欧和一些其他地区的语言 \u0026hellip; GBK: 主要用于简体中文 Big5: 用于繁体中文 \u0026hellip; 3.为什么有时候我们打开文件会看到乱码？ 我们知道同一个字符在不同的字符编码下可能会被转化成不同的二进制，同一个二进制在不同字符编码下可能会被解释成不同的符号。当选用的这个字符编码中不包含该二进制对应的字符时我们就看到了乱码现象。因此当打开一个文本文件时，我们就必须知道它的编码方式。\n4. ASCII（American Standard Code for Information Interchange） ASCII是一种最早的字符编码标准，它于20世纪60年代初由美国发布，规定了英语和二进制位之间的关系。它规定了128种字符，具体有哪128种可查询对应的表格资料，比如字母A对应的二进制是0100 0001。\n但是很明显，区区只有128种对于其他语言的字符则不足够，比如光常用汉字就有几千个，那我们怎么处理汉字呢？\n聪明的同学可能想到了上面提到的GBK和Big5是用来处理简繁体中文的，那么假如一段文本中既包含中文又包含一些特殊的拉丁字母呢？此时应该用什么字符编码来存储和打开这个文本文件呢？\n面对多元的文化环境，如果能有一种字符编码能包含世界上所有的字符是不是会更加方便。于是，Unicode应运而生。\n5. Unicode Unicode旨在涵盖全球范围内的所有语言和字符。它规定了每一个字符所对应的数字，比如中文“嗨” 对应的二进制是101010111101000，但是unicode 却并没有规定怎么存储，假如我们直接高位补0把101010111101000存到计算机中，那读取的时候怎么解释呢？计算机怎么知道这16位二进制(2字节）是表示一个字符还是两个字符？\n那为什么unicode 不规定就2个字节表示一个字符呢 因为在unicode中一个字符可能需要占用1～n字节不等，为了适配所有字符，就必须规定n(n\u0026gt;1)字节表示一个字符，那对于那些明明一个字节就可以表示的字符，却非要用n字节来表示，造成了空间的浪费。\n重点：Unicode 只规定了字符和数字的映射关系，但却没有规定这些数字怎么存储，当我们把某个字符对应的数字理解为这个字符对应的unicode时，unicode 并没有告诉我们这个unicode 该如何存储到计算机中。\n6.UTF-8（Unicode Transformation Format） 由于Unicode 没有规定存储方式，导致unicode 有多种实现方式, 其中UTF-8是其中一种最常见的实现方式。\nUTF-8是一种针对Unicode设计的可变长度字符编码方案。对于常用的英文字母和符号，其编码与ASCII兼容，它使用8位二进制数（1字节）来表示。但对于那些不属于ASCII字符集的Unicode字符，UTF-8采用了不同的编码方式。\n其编码规则：\n1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。\n2）对于n字节的符号（n \u0026gt; 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，从低位开始逐渐补全为这个符号的 Unicode 码，高位不足的补0。\n字符 Unicode unicode 二进制 UTF-8编码方式 说明 A U+0041 01000001 01000001 对于单字节的符号，字节的第一位设为0 é U+00E9 11101001 11000011 10101001 n=2 中 U+4e2d 100111000101101 11100100 10111000 10101101 n=3 😄 U+1F601 11111011000000100 11110000 10011111 10011000 10000001 n=4 你没看错，unicode 也可以表示表情包符号。对于更详细的UTF-8编码规则可参阅相关文档。\n总结 字符编码用来规定字符和数值(码位）之间，以及码位和计算机二进制之间的一一对应关系，不同的字符编码这个映射关系不同 ASCII是一种最早的字符编码标准用来处理英文及常见标点等128种字符，而Unicode 包含更多的字符集，旨在为世界上几乎所有的字符提供一个唯一的数值标识，以便在不同的计算机系统和应用程序中进行一致的文本处理，因此ASCII字符集是Unicode字符集的一个子集。 Unicode 并不规定码位的存储方式，它的存储和表现方式取决于具体的编码方案，其中最常见的是UTF-8, 此外还有UTF-16, UTF-32等。UTF-8是unicode 的一种具体实现。 ","date":"2024-01-02T14:38:04+08:00","image":"http://localhost:1313/posts/ascii-unicode-and-charset/images/birds_hu5d1795c6e08ed878cbfdb3775942dd39_211231_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/posts/ascii-unicode-and-charset/","title":"ASCII、Unicode和UTF-8与字符编码"},{"content":"Hello world and hello hugo.\n","date":"2023-11-05T14:16:30+08:00","image":"http://localhost:1313/posts/hello-hugo/images/blue_sky_hu1b20aecede543d83af89b7e5ec0a8a40_246301_120x120_fill_box_smart1_3.png","permalink":"http://localhost:1313/posts/hello-hugo/","title":"Hello Hugo"}]